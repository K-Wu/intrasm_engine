{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This jupyter notebook shows an example to use torch profiler to profile the huggingface model, export the data, and enable module-wise profiling.\n",
    "\n",
    "### Reference\n",
    "\n",
    "1. [hf_pipeline_prof.py](https://github.com/yqhu/profiler-workshop/blob/c8d4a7c30a61cc7b909d89f88f5fd36b70c55769/hf_pipeline_prof.py) demonstrates how to export the profiling results as json traces and FlameGraph.\n",
    "2. [hf_training_trainer_prof.py](https://github.com/yqhu/profiler-workshop/blob/c8d4a7c30a61cc7b909d89f88f5fd36b70c55769/hf_training_trainer_prof.py) demonstrates how to profile a huggingface model via registering TrainerCallback.\n",
    "3. [hf_training_torch_prof.py](https://github.com/yqhu/profiler-workshop/blob/c8d4a7c30a61cc7b909d89f88f5fd36b70c55769/hf_training_torch_prof.py) demonstrates how to run the Huggingface model in steps and profile it via PyTorch profiler in native manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccddb2ed9964130a8bc10224d033784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='459' max='459' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [459/459 00:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.419967</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.871886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "STAGE:2024-01-12 10:36:41 3120620:3120620 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-01-12 10:36:41 3120620:3120620 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-01-12 10:36:41 3120620:3120620 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "STAGE:2024-01-12 10:36:45 3120620:3120620 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-01-12 10:36:45 3120620:3120620 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-01-12 10:36:45 3120620:3120620 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "/tmp/ipykernel_3120620/2433832331.py:33: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"glue\", \"mrpc\")\n",
      "/home/kwu/anaconda3/envs/dev_cupy_graph/lib/python3.11/site-packages/datasets/load.py:752: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time, 29.9 s\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"sentence1\"], example[\"sentence2\"], truncation=True\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=2\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test-trainer\", evaluation_strategy=\"epoch\", num_train_epochs=1, fp16=True\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "\n",
    "class ProfCallback(TrainerCallback):\n",
    "    def __init__(self, prof):\n",
    "        self.prof = prof\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        self.prof.step()\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        skip_first=3, wait=1, warmup=1, active=2, repeat=2\n",
    "    ),\n",
    "    # on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
    "    #    \"hf-training-trainer\"\n",
    "    # ), # This saves the trace to disk\n",
    "    profile_memory=True,\n",
    "    with_stack=True,\n",
    "    with_modules=True,\n",
    "    # The following is needed to not export empty stack https://github.com/pytorch/pytorch/issues/100253#issuecomment-1579804477\n",
    "    experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True),\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "    trainer.add_callback(ProfCallback(prof=prof))\n",
    "    trainer.train()\n",
    "\n",
    "print(f\"training time, {(time.perf_counter() - start):.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.591ms         6.09%       3.591ms     156.130us           0 b           0 b           0 b           0 b            23  \n",
      "                                          ProfilerStep*        47.17%      90.535ms        74.91%     143.789ms      71.894ms       0.000us         0.00%      34.540ms      17.270ms           0 b           0 b           0 b      -2.19 Gb             2  \n",
      "                                               aten::to         1.30%       2.493ms        14.32%      27.494ms      15.394us       0.000us         0.00%       4.841ms       2.711us       1.04 Kb        -664 b       1.44 Gb     109.85 Mb          1786  \n",
      "                                         aten::_to_copy         2.58%       4.947ms        13.66%      26.212ms      19.649us       0.000us         0.00%       5.221ms       3.914us       1.57 Kb         508 b       1.44 Gb           0 b          1334  \n",
      "                                    aten::empty_strided         3.17%       6.080ms         3.17%       6.080ms       3.217us       0.000us         0.00%       0.000us       0.000us        1008 b        1008 b       2.39 Gb       2.39 Gb          1890  \n",
      "                                            aten::copy_         3.27%       6.269ms        10.14%      19.458ms      12.651us       6.166ms        10.45%       6.166ms       4.009us         240 b         240 b           0 b           0 b          1538  \n",
      "                                        cudaMemcpyAsync         1.15%       2.204ms         1.15%       2.204ms     110.200us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            20  \n",
      "                                  cudaStreamSynchronize         3.89%       7.472ms         3.89%       7.472ms     533.714us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            14  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.265ms         5.53%       3.265ms     136.042us           0 b           0 b           0 b           0 b            24  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.323ms         5.63%       3.323ms     138.458us           0 b           0 b           0 b           0 b            24  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.303ms         5.60%       3.303ms     137.625us           0 b           0 b           0 b           0 b            24  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.218ms        10.54%       6.218ms     230.296us           0 b           0 b           0 b           0 b            27  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.238ms         5.49%       3.238ms     179.889us           0 b           0 b           0 b           0 b            18  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       2.219ms         3.76%       2.219ms     123.278us           0 b           0 b           0 b           0 b            18  \n",
      "at::native::amp_update_scale_cuda_kernel(float*, int...         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us         0.01%       3.000us       1.000us           0 b           0 b           0 b           0 b             3  \n",
      "                         Memcpy HtoD (Pinned -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       0.250us           0 b           0 b           0 b           0 b             8  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         1.10%       2.117ms         1.18%       2.256ms       1.128ms       0.000us         0.00%       0.000us       0.000us           0 b     -27.31 Kb           0 b           0 b             2  \n",
      "                                            aten::empty         1.22%       2.339ms         1.22%       2.339ms       3.898us       0.000us         0.00%       0.000us       0.000us      27.31 Kb      27.31 Kb     638.45 Mb     638.45 Mb           600  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  \n",
      "                                          aten::detach_         0.00%       5.000us         0.00%       6.000us       0.750us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  \n",
      "                                                detach_         0.00%       1.000us         0.00%       1.000us       0.125us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  \n",
      "                                       aten::pin_memory         0.01%      20.000us         0.06%     119.000us      14.875us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  \n",
      "                                        aten::is_pinned         0.02%      33.000us         0.02%      42.000us       5.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  \n",
      "                               cudaPointerGetAttributes         0.00%       9.000us         0.00%       9.000us       1.125us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  \n",
      "                                      aten::_pin_memory         0.02%      42.000us         0.03%      56.000us       7.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  \n",
      "                                             aten::set_         0.00%       3.000us         0.00%       3.000us       0.375us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  \n",
      "                                            aten::slice         0.02%      46.000us         0.03%      54.000us       4.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  \n",
      "                                       aten::as_strided         0.03%      56.000us         0.03%      56.000us       0.028us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1998  \n",
      "                                        aten::unsqueeze         0.06%     111.000us         0.06%     111.000us       0.273us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           406  \n",
      "                                       cudaLaunchKernel         6.75%      12.954ms         6.75%      12.954ms       4.735us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2736  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.409ms         4.08%       2.409ms       5.655us           0 b           0 b           0 b           0 b           426  \n",
      "                                             aten::rsub         0.01%      13.000us         0.03%      57.000us      28.500us       0.000us         0.00%       2.000us       1.000us           0 b           0 b       5.00 Kb           0 b             2  \n",
      "                                              aten::sub         0.02%      30.000us         0.02%      44.000us      22.000us       2.000us         0.00%       2.000us       1.000us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       1.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::mul         0.13%     255.000us         0.23%     440.000us      13.750us     143.000us         0.24%     143.000us       4.469us           0 b           0 b      51.79 Mb      51.79 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.01%       4.000us       1.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                        aten::embedding         0.03%      61.000us         0.12%     225.000us      37.500us       0.000us         0.00%      30.000us       5.000us           0 b           0 b       8.12 Mb           0 b             6  \n",
      "                                          aten::reshape         0.64%       1.233ms         3.03%       5.822ms       7.503us       0.000us         0.00%     848.000us       1.093us           0 b           0 b     144.70 Mb           0 b           776  \n",
      "                                             aten::view         0.78%       1.490ms         0.78%       1.490ms       1.369us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1088  \n",
      "                                     aten::index_select         0.04%      76.000us         0.08%     152.000us      25.333us      30.000us         0.05%      30.000us       5.000us           0 b           0 b       8.12 Mb           0 b             6  \n",
      "                                          aten::resize_         0.01%      26.000us         0.01%      26.000us       2.600us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       8.12 Mb       8.12 Mb            10  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      30.000us         0.05%      30.000us       5.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                              aten::add         0.48%     919.000us         0.67%       1.282ms      16.868us     435.000us         0.74%     435.000us       5.724us           0 b           0 b     148.22 Mb     148.22 Mb            76  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     503.000us         0.85%     503.000us       5.030us           0 b           0 b           0 b           0 b           100  \n",
      "                                             aten::add_         0.83%       1.592ms         1.73%       3.329ms       6.222us     505.000us         0.86%     505.000us       0.944us       1.41 Kb          24 b           0 b           0 b           535  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       8.000us         0.01%       8.000us       4.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                       aten::layer_norm         0.18%     341.000us         1.15%       2.205ms      39.375us       0.000us         0.00%     290.000us       5.179us           0 b           0 b     106.36 Mb       9.06 Mb            56  \n",
      "                                aten::native_layer_norm         0.51%     980.000us         0.95%       1.826ms      36.520us     290.000us         0.49%     290.000us       5.800us           0 b           0 b      95.44 Mb           0 b            50  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     290.000us         0.49%     290.000us       5.800us           0 b           0 b           0 b           0 b            50  \n",
      "                                          aten::dropout         0.09%     173.000us         1.37%       2.624ms      34.526us       0.000us         0.00%     319.000us       4.197us           0 b           0 b     130.54 Mb       2.86 Mb            76  \n",
      "                                   aten::native_dropout         0.60%       1.157ms         1.29%       2.484ms      32.684us     324.000us         0.55%     324.000us       4.263us           0 b           0 b     130.54 Mb      -1.14 Mb            76  \n",
      "                                       aten::empty_like         0.39%     748.000us         1.32%       2.537ms       6.012us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     391.25 Mb      16.96 Mb           422  \n",
      "                                  cudaStreamIsCapturing         0.00%       3.000us         0.00%       3.000us       0.038us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            78  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us     116.000us         0.20%     116.000us       4.462us           0 b           0 b           0 b           0 b            26  \n",
      "                                           aten::linear         1.11%       2.126ms        12.24%      23.497ms      79.382us       0.000us         0.00%      11.815ms      39.916us           0 b           0 b     850.62 Mb     -22.35 Mb           296  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.809ms         4.76%       2.809ms       5.733us           0 b           0 b           0 b           0 b           490  \n",
      "                                                aten::t         0.70%       1.343ms         1.28%       2.453ms       3.315us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           740  \n",
      "                                        aten::transpose         0.80%       1.526ms         0.80%       1.544ms       1.747us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           884  \n",
      "                                            aten::addmm         1.94%       3.721ms         2.35%       4.511ms      30.480us       4.756ms         8.06%       4.756ms      32.135us           0 b           0 b     187.15 Mb     187.15 Mb           148  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.00%       7.000us         0.00%       7.000us       0.058us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           120  \n",
      "ampere_fp16_s16816gemm_fp16_128x64_ldg8_relu_f2f_sta...         0.00%       0.000us         0.00%       0.000us       0.000us     913.000us         1.55%     913.000us      19.021us           0 b           0 b           0 b           0 b            48  \n",
      "                                          aten::permute         0.32%     622.000us         0.33%     639.000us       3.328us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           192  \n",
      "                                           aten::matmul         0.36%     693.000us         3.49%       6.693ms      92.958us       0.000us         0.00%       1.121ms      15.569us           0 b           0 b     183.93 Mb       1.59 Mb            72  \n",
      "                                           aten::expand         0.17%     320.000us         0.17%     323.000us       3.365us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            96  \n",
      "                                            aten::clone         0.35%     668.000us         2.17%       4.158ms      21.656us       0.000us         0.00%     901.000us       4.693us           0 b           0 b     165.38 Mb      -4.37 Mb           192  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     926.000us         1.57%     926.000us       4.823us           0 b           0 b           0 b           0 b           192  \n",
      "                                     aten::_unsafe_view         0.17%     321.000us         0.17%     321.000us       1.486us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           216  \n",
      "                                              aten::bmm         1.18%       2.259ms         1.54%       2.952ms      20.500us       1.213ms         2.06%       1.213ms       8.424us           0 b           0 b     139.69 Mb     139.69 Mb           144  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.01%      25.000us         0.01%      25.000us       0.140us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           178  \n",
      "void cutlass::Kernel<cutlass_75_tensorop_f16_s1688ge...         0.00%       0.000us         0.00%       0.000us       0.000us     120.000us         0.20%     120.000us      10.000us           0 b           0 b           0 b           0 b            12  \n",
      "                                              aten::div         0.33%     640.000us         0.47%     907.000us      16.796us     102.000us         0.17%     102.000us       1.889us           0 b           0 b      57.87 Mb      57.87 Mb            54  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      96.000us         0.16%      96.000us       2.000us           0 b           0 b           0 b           0 b            48  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     168.000us         0.28%     168.000us       7.000us           0 b           0 b           0 b           0 b            24  \n",
      "                                          aten::softmax         0.06%     123.000us         0.28%     532.000us      20.462us       0.000us         0.00%     132.000us       5.077us           0 b           0 b      55.50 Mb       2.00 Mb            26  \n",
      "                                         aten::_softmax         0.15%     291.000us         0.20%     391.000us      16.292us     132.000us         0.22%     132.000us       5.500us           0 b           0 b      51.21 Mb      51.21 Mb            24  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us     132.000us         0.22%     132.000us       5.500us           0 b           0 b           0 b           0 b            24  \n",
      "void cutlass::Kernel<cutlass_75_tensorop_f16_s1688ge...         0.00%       0.000us         0.00%       0.000us       0.000us      96.000us         0.16%      96.000us       8.000us           0 b           0 b           0 b           0 b            12  \n",
      "                                       aten::contiguous         0.07%     130.000us         0.29%     551.000us      22.958us       0.000us         0.00%      60.000us       2.500us           0 b           0 b      20.67 Mb       4.50 Mb            24  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us     208.000us         0.35%     208.000us       4.160us           0 b           0 b           0 b           0 b            50  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     259.000us         0.44%     259.000us       5.396us           0 b           0 b           0 b           0 b            48  \n",
      "                                   cudaFuncSetAttribute         0.02%      38.000us         0.02%      38.000us       0.157us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           242  \n",
      "sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x12...         0.00%       0.000us         0.00%       0.000us       0.000us       1.780ms         3.02%       1.780ms      74.167us           0 b           0 b           0 b           0 b            24  \n",
      "                                             aten::gelu         0.16%     309.000us         0.23%     447.000us      18.625us     168.000us         0.28%     168.000us       7.000us           0 b           0 b      83.64 Mb      83.64 Mb            24  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     168.000us         0.28%     168.000us       7.000us           0 b           0 b           0 b           0 b            24  \n",
      "ampere_fp16_s16816gemm_fp16_64x128_ldg8_relu_f2f_sta...         0.00%       0.000us         0.00%       0.000us       0.000us     780.000us         1.32%     780.000us      65.000us           0 b           0 b           0 b           0 b            12  \n",
      "                                           aten::select         0.23%     438.000us         0.23%     440.000us       1.084us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           406  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.01%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  \n",
      "void cutlass::Kernel<cutlass_80_wmma_tensorop_f16_s1...         0.00%       0.000us         0.00%       0.000us       0.000us      10.000us         0.02%      10.000us       5.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::tanh         0.02%      33.000us         0.02%      45.000us      22.500us       2.000us         0.00%       2.000us       1.000us           0 b           0 b      24.00 Kb      24.00 Kb             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       1.000us           0 b           0 b           0 b           0 b             2  \n",
      "void cutlass::Kernel<cutlass_80_wmma_tensorop_f16_s1...         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.01%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  \n",
      "void splitKreduce_kernel<32, 16, int, __half, __half...         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.01%       4.000us       2.000us           0 b           0 b           0 b           0 b             2  \n",
      "                               aten::cross_entropy_loss         0.01%      12.000us         0.09%     171.000us      85.500us       0.000us         0.00%       8.000us       4.000us           0 b           0 b       4.00 Kb           0 b             2  \n",
      "                                      aten::log_softmax         0.00%       8.000us         0.03%      54.000us      27.000us       0.000us         0.00%       2.000us       1.000us           0 b           0 b       1.00 Kb           0 b             2  \n",
      "                                     aten::_log_softmax         0.02%      32.000us         0.02%      46.000us      23.000us       2.000us         0.00%       2.000us       1.000us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
      "void (anonymous namespace)::softmax_warp_forward<c10...         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       1.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                      aten::nll_loss_nd        -0.01%     -18.000us         0.05%     105.000us      52.500us       0.000us         0.00%       6.000us       3.000us           0 b           0 b       3.00 Kb      -1.00 Kb             2  \n",
      "                                         aten::nll_loss         0.02%      35.000us         0.08%     148.000us      37.000us       0.000us         0.00%       8.000us       2.000us           0 b           0 b       5.00 Kb       1.00 Kb             4  \n",
      "                                 aten::nll_loss_forward         0.02%      32.000us         0.02%      44.000us      22.000us       4.000us         0.01%       4.000us       2.000us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
      "void at::native::(anonymous namespace)::nll_loss_for...         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.01%       4.000us       2.000us           0 b           0 b           0 b           0 b             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 191.939ms\n",
      "Self CUDA time total: 59.001ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "prof.export_stacks(\"stacks.json\", \"self_cuda_time_total\")\n",
    "# use Brendan Gregg's FlameGraph tool to generate flamegraph/flamechart\n",
    "# git clone https://github.com/brendangregg/FlameGraph\n",
    "# ../FlameGraph/flamegraph.pl --title \"FlameGraph\" --countname \"us.\" stacks.json > perf_viz.svg\n",
    "# ../FlameGraph/flamegraph.pl --title \"FlameChart\" --countname \"us.\" --flamechart stacks.json > perf_chart.svg\n",
    "!/home/kwu/FlameGraph/flamegraph.pl --title \"FlameGraph\" --countname \"us.\" stacks.json > perf_viz.svg\n",
    "!/home/kwu/FlameGraph/flamegraph.pl --title \"FlameChart\" --countname \"us.\" --flamechart stacks.json > perf_chart.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_cupy_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
