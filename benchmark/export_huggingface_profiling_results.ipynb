{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This jupyter notebook shows an example to use torch profiler to profile the huggingface model, export the data, and enable module-wise profiling.\n",
    "\n",
    "### Reference\n",
    "\n",
    "1. [hf_pipeline_prof.py](https://github.com/yqhu/profiler-workshop/blob/c8d4a7c30a61cc7b909d89f88f5fd36b70c55769/hf_pipeline_prof.py) demonstrates how to export the profiling results as json traces and FlameGraph.\n",
    "2. [hf_training_trainer_prof.py](https://github.com/yqhu/profiler-workshop/blob/c8d4a7c30a61cc7b909d89f88f5fd36b70c55769/hf_training_trainer_prof.py) demonstrates how to profile a huggingface model via registering TrainerCallback.\n",
    "3. [hf_training_torch_prof.py](https://github.com/yqhu/profiler-workshop/blob/c8d4a7c30a61cc7b909d89f88f5fd36b70c55769/hf_training_torch_prof.py) demonstrates how to run the Huggingface model in steps and profile it via PyTorch profiler in native manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='459' max='459' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [459/459 00:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.386602</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.884354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "[W kineto_shim.cpp:372] Profiler is not initialized: skipping step() invocation\n",
      "STAGE:2024-01-17 12:42:18 2376418:2376418 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-01-17 12:42:18 2376418:2376418 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-01-17 12:42:18 2376418:2376418 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "STAGE:2024-01-17 12:42:23 2376418:2376418 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-01-17 12:42:23 2376418:2376418 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-01-17 12:42:23 2376418:2376418 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "/tmp/ipykernel_2376418/3719306836.py:33: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"glue\", \"mrpc\")\n",
      "/home/kwu/anaconda3/envs/dev_cupy_graph/lib/python3.11/site-packages/datasets/load.py:752: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time, 33.0 s\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"sentence1\"], example[\"sentence2\"], truncation=True\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=2\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test-trainer\", evaluation_strategy=\"epoch\", num_train_epochs=1, fp16=True\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "\n",
    "class ProfCallback(TrainerCallback):\n",
    "    def __init__(self, prof):\n",
    "        self.prof = prof\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        self.prof.step()\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        skip_first=3, wait=1, warmup=1, active=2, repeat=2\n",
    "    ),\n",
    "    # on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
    "    #    \"hf-training-trainer\"\n",
    "    # ), # This saves the trace to disk\n",
    "    # on_trace_ready=torch.profiler.tensorboard_trace_handler(\"test_tensorboard\")\n",
    "    profile_memory=True,\n",
    "    with_stack=True,\n",
    "    with_modules=True,\n",
    "    # The following is needed to not export empty stack https://github.com/pytorch/pytorch/issues/100253#issuecomment-1579804477\n",
    "    experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True),\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "    # with torch.autograd.profiler.profile(\n",
    "    #         # on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
    "    #         #    \"hf-training-trainer\"\n",
    "    #         # ), # This saves the trace to disk\n",
    "    #         with_modules=True,\n",
    "    #         # The following is needed to not export empty stack https://github.com/pytorch/pytorch/issues/100253#issuecomment-1579804477\n",
    "    #         experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True),\n",
    "    #     ) as prof2:\n",
    "    trainer.add_callback(ProfCallback(prof=prof))\n",
    "    trainer.train()\n",
    "\n",
    "print(f\"training time, {(time.perf_counter() - start):.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Source Location                                                              \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "                                          ProfilerStep*        25.32%      55.195ms        41.42%      90.313ms      90.313ms       0.000us         0.00%      17.862ms      17.862ms           0 b          -8 b       1.50 Kb      -1.14 Gb             1  ...method _record_function_enter_new of PyCapsule object at 0x7ff560de1200>  \n",
      "                                                                                                                                                                                                                                                             torch/_ops.py(687): __call__                                                 \n",
      "                                                                                                                                                                                                                                                             torch/autograd/profiler.py(630): __enter__                                   \n",
      "                                                                                                                                                                                                                                                             torch/profiler/profiler.py(636): step                                        \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(64): on_step_end                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      47.000us         0.08%      47.000us      47.000us           0 b           0 b           0 b           0 b             1  ...method _record_function_enter_new of PyCapsule object at 0x7ff560de1200>  \n",
      "                                                                                                                                                                                                                                                             torch/_ops.py(687): __call__                                                 \n",
      "                                                                                                                                                                                                                                                             torch/autograd/profiler.py(630): __enter__                                   \n",
      "                                                                                                                                                                                                                                                             torch/profiler/profiler.py(636): step                                        \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(64): on_step_end                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       1.102ms         1.92%       1.102ms     137.750us           0 b           0 b           0 b           0 b             8  transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3508): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3448): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                               aten::to         0.02%      35.000us         2.21%       4.814ms     962.800us       0.000us         0.00%       3.000us       0.600us           0 b           0 b      19.00 Kb           0 b             5  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(161): <dictcomp>                              \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/data_loader.py(460): __iter__                                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                         aten::_to_copy         0.02%      48.000us         2.19%       4.779ms     955.800us       0.000us         0.00%       3.000us       0.600us           0 b           0 b      19.00 Kb           0 b             5  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(161): <dictcomp>                              \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/data_loader.py(460): __iter__                                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                    aten::empty_strided         0.02%      54.000us         0.02%      54.000us      10.800us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      19.00 Kb      19.00 Kb             5  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(161): <dictcomp>                              \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/data_loader.py(460): __iter__                                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::copy_         0.03%      56.000us         2.15%       4.677ms     935.400us       3.000us         0.01%       3.000us       0.600us           0 b           0 b           0 b           0 b             5  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(161): <dictcomp>                              \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/data_loader.py(460): __iter__                                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                        cudaMemcpyAsync         0.04%      77.000us         0.04%      77.000us      15.400us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             5  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(161): <dictcomp>                              \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/data_loader.py(460): __iter__                                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                  cudaStreamSynchronize         2.08%       4.544ms         2.08%       4.544ms     908.800us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             5  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(161): <dictcomp>                              \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/data_loader.py(460): __iter__                                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       1.102ms         1.92%       1.102ms     137.750us           0 b           0 b           0 b           0 b             8  transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3508): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3448): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       2.061ms         3.58%       2.061ms     229.000us           0 b           0 b           0 b           0 b             9  transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3508): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3448): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       7.000us         0.01%       7.000us       3.500us           0 b           0 b           0 b           0 b             2  transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3508): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3448): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       5.000us         0.01%       5.000us       2.500us           0 b           0 b           0 b           0 b             2  transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3508): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3448): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.01%       6.000us       2.000us           0 b           0 b           0 b           0 b             3  transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3508): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3448): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.01%       4.000us       2.000us           0 b           0 b           0 b           0 b             2  transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3508): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3448): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "at::native::amp_update_scale_cuda_kernel(float*, int...         0.00%       0.000us         0.00%       0.000us       0.000us       1.000us         0.00%       1.000us       1.000us           0 b           0 b           0 b           0 b             1  transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3508): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3448): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                         Memcpy HtoD (Pinned -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us         0.01%       3.000us       0.600us           0 b           0 b           0 b           0 b             5  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(161): <dictcomp>                              \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             accelerate/data_loader.py(460): __iter__                                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                               aten::to         0.00%       8.000us         0.05%     105.000us      35.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      10.50 Kb           0 b             3  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                         aten::_to_copy         0.01%      19.000us         0.04%      97.000us      32.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      10.50 Kb           0 b             3  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                    aten::empty_strided         0.01%      22.000us         0.01%      22.000us       7.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      10.50 Kb      10.50 Kb             3  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::copy_         0.01%      20.000us         0.03%      56.000us      18.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                        cudaMemcpyAsync         0.01%      27.000us         0.01%      27.000us       9.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                         Memcpy HtoD (Pinned -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                  cudaStreamSynchronize         0.00%       9.000us         0.00%       9.000us       3.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             accelerate/utils/operations.py(138): send_to_device                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1912): _inner_training_loop                          \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(1537): train                                         \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_2376418/3719306836.py(94): <module>                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         1.19%       2.590ms         1.29%       2.806ms       1.403ms       0.000us         0.00%       0.000us       0.000us           0 b     -23.06 Kb           0 b           0 b             2  ...method _record_function_enter_new of PyCapsule object at 0x7ff560de1200>  \n",
      "                                                                                                                                                                                                                                                             torch/_ops.py(687): __call__                                                 \n",
      "                                                                                                                                                                                                                                                             torch/autograd/profiler.py(630): __enter__                                   \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/dataloader.py(625): __next__                                \n",
      "                                                                                                                                                                                                                                                             <built-in function next>                                                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::empty         0.02%      41.000us         0.02%      41.000us       5.125us       0.000us         0.00%       0.000us       0.000us      23.06 Kb      23.06 Kb           0 b           0 b             8  <built-in method tensor of type object at 0x7ff563e97aa0>                    \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(717): as_tensor                      \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(680): convert_to_tensors             \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(203): __init__                       \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(3128): pad                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                               aten::to         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method tensor of type object at 0x7ff563e97aa0>                    \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(717): as_tensor                      \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(680): convert_to_tensors             \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(203): __init__                       \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(3128): pad                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method tensor of type object at 0x7ff563e97aa0>                    \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(717): as_tensor                      \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(680): convert_to_tensors             \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(203): __init__                       \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(3128): pad                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::detach_         0.00%       8.000us         0.01%      12.000us       1.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method tensor of type object at 0x7ff563e97aa0>                    \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(717): as_tensor                      \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(680): convert_to_tensors             \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(203): __init__                       \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(3128): pad                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                                detach_         0.00%       4.000us         0.00%       4.000us       0.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method tensor of type object at 0x7ff563e97aa0>                    \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(717): as_tensor                      \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(680): convert_to_tensors             \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(203): __init__                       \n",
      "                                                                                                                                                                                                                                                             transformers/tokenization_utils_base.py(3128): pad                           \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       aten::pin_memory         0.01%      22.000us         0.07%     163.000us      20.375us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method pin_memory of Tensor object at 0x7ff4a835d010>              \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(63): <dictcomp>                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/dataloader.py(672): _next_data                              \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                        aten::is_pinned         0.02%      47.000us         0.03%      60.000us       7.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method pin_memory of Tensor object at 0x7ff4a835d010>              \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(63): <dictcomp>                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/dataloader.py(672): _next_data                              \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                               cudaPointerGetAttributes         0.01%      14.000us         0.01%      14.000us       1.750us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method pin_memory of Tensor object at 0x7ff4a835d010>              \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(63): <dictcomp>                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/dataloader.py(672): _next_data                              \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                      aten::_pin_memory         0.03%      55.000us         0.04%      80.000us      10.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method pin_memory of Tensor object at 0x7ff4a835d010>              \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(63): <dictcomp>                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/dataloader.py(672): _next_data                              \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                             aten::set_         0.00%       4.000us         0.00%       4.000us       0.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method pin_memory of Tensor object at 0x7ff4a835d010>              \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(63): <dictcomp>                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/dataloader.py(672): _next_data                              \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::copy_         0.01%      21.000us         0.01%      21.000us       2.625us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method pin_memory of Tensor object at 0x7ff4a835d010>              \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(63): <dictcomp>                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/_utils/pin_memory.py(56): pin_memory                        \n",
      "                                                                                                                                                                                                                                                             torch/utils/data/dataloader.py(672): _next_data                              \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                               aten::to         0.00%       2.000us         0.00%       2.000us       0.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(2657): _prepare_input                                \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(2662): <dictcomp>                                    \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(2657): _prepare_input                                \n",
      "                                                                                                                                                                                                                                                             transformers/trainer.py(2675): _prepare_inputs                               \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::slice         0.02%      34.000us         0.02%      39.000us       9.750us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(1535): forward                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       aten::as_strided         0.00%       5.000us         0.00%       5.000us       0.625us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             8  transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(1535): forward                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                        aten::unsqueeze         0.01%      14.000us         0.01%      14.000us       3.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(1535): forward                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                               aten::to         0.00%       4.000us         0.07%     149.000us      74.500us       0.000us         0.00%       4.000us       2.000us           0 b           0 b       5.00 Kb           0 b             2  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                         aten::_to_copy         0.01%      18.000us         0.07%     145.000us      72.500us       0.000us         0.00%       4.000us       2.000us           0 b           0 b       5.00 Kb           0 b             2  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                    aten::empty_strided         0.01%      25.000us         0.01%      25.000us      12.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       5.00 Kb       5.00 Kb             2  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::copy_         0.02%      37.000us         0.05%     102.000us      51.000us       4.000us         0.01%       4.000us       2.000us           0 b           0 b           0 b           0 b             2  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.03%      65.000us         0.03%      65.000us      32.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.01%       4.000us       2.000us           0 b           0 b           0 b           0 b             2  <built-in method to of Tensor object at 0x7ff4a904c7d0>                      \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                             aten::rsub         0.01%      19.000us         0.04%      82.000us      41.000us       0.000us         0.00%       2.000us       1.000us           8 b           8 b       5.00 Kb           0 b             2  <built-in method rsub of type object at 0x7ff563e97aa0>                      \n",
      "                                                                                                                                                                                                                                                             torch/_tensor.py(907): __rsub__                                              \n",
      "                                                                                                                                                                                                                                                             torch/_tensor.py(34): wrapped                                                \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                              aten::sub         0.02%      45.000us         0.03%      63.000us      31.500us       2.000us         0.00%       2.000us       1.000us           0 b           0 b       5.00 Kb       5.00 Kb             2  <built-in method rsub of type object at 0x7ff563e97aa0>                      \n",
      "                                                                                                                                                                                                                                                             torch/_tensor.py(907): __rsub__                                              \n",
      "                                                                                                                                                                                                                                                             torch/_tensor.py(34): wrapped                                                \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.01%      18.000us         0.01%      18.000us       9.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  <built-in method rsub of type object at 0x7ff563e97aa0>                      \n",
      "                                                                                                                                                                                                                                                             torch/_tensor.py(907): __rsub__                                              \n",
      "                                                                                                                                                                                                                                                             torch/_tensor.py(34): wrapped                                                \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       1.000us           0 b           0 b           0 b           0 b             2  <built-in method rsub of type object at 0x7ff563e97aa0>                      \n",
      "                                                                                                                                                                                                                                                             torch/_tensor.py(907): __rsub__                                              \n",
      "                                                                                                                                                                                                                                                             torch/_tensor.py(34): wrapped                                                \n",
      "                                                                                                                                                                                                                                                             transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                              aten::mul         0.01%      29.000us         0.02%      43.000us      21.500us       2.000us         0.00%       2.000us       1.000us           0 b           0 b       5.00 Kb       5.00 Kb             2  transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(1535): forward                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.01%      14.000us         0.01%      14.000us       7.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(1535): forward                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.000us         0.00%       2.000us       1.000us           0 b           0 b           0 b           0 b             2  transformers/modeling_utils.py(921): get_extended_attention_mask             \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertModel_0                                                       \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(1535): forward                     \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::slice         0.01%      13.000us         0.01%      15.000us       3.750us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  transformers/models/bert/modeling_bert.py(202): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertEmbeddings_0                                                  \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       aten::as_strided         0.00%       2.000us         0.00%       2.000us       0.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  transformers/models/bert/modeling_bert.py(202): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertEmbeddings_0                                                  \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                        aten::embedding         0.02%      43.000us         0.06%     137.000us      68.500us       0.000us         0.00%      13.000us       6.500us           0 b           0 b       4.00 Mb           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::reshape         0.00%       7.000us         0.00%       9.000us       4.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                             aten::view         0.00%       2.000us         0.00%       2.000us       0.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                     aten::index_select         0.02%      45.000us         0.04%      85.000us      42.500us      13.000us         0.02%      13.000us       6.500us           0 b           0 b       4.00 Mb           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::empty         0.00%       8.000us         0.00%       8.000us       4.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::resize_         0.01%      12.000us         0.01%      12.000us       6.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       4.00 Mb       4.00 Mb             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.01%      20.000us         0.01%      20.000us      10.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      13.000us         0.02%      13.000us       6.500us           0 b           0 b           0 b           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                        aten::embedding         0.01%      18.000us         0.03%      69.000us      34.500us       0.000us         0.00%      12.000us       6.000us           0 b           0 b       4.00 Mb           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_1                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::reshape         0.00%       3.000us         0.00%       4.000us       2.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_1                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                             aten::view         0.00%       1.000us         0.00%       1.000us       0.167us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_1                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                     aten::index_select         0.01%      22.000us         0.02%      47.000us      23.500us      12.000us         0.02%      12.000us       6.000us           0 b           0 b       4.00 Mb           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_1                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::empty         0.01%      15.000us         0.01%      15.000us       3.750us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.00 Kb      12.00 Kb             4  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_1                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::resize_         0.00%       6.000us         0.00%       6.000us       3.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       4.00 Mb       4.00 Mb             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_1                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.01%      32.000us         0.01%      32.000us       5.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_1                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us         0.02%      12.000us       6.000us           0 b           0 b           0 b           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_1                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                              aten::add         0.01%      30.000us         0.02%      42.000us      21.000us       6.000us         0.01%       6.000us       3.000us           0 b           0 b       4.00 Mb       4.00 Mb             2  transformers/models/bert/modeling_bert.py(202): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertEmbeddings_0                                                  \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.01%      22.000us         0.01%      22.000us       5.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  transformers/models/bert/modeling_bert.py(202): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertEmbeddings_0                                                  \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.01%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  transformers/models/bert/modeling_bert.py(202): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertEmbeddings_0                                                  \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                        aten::embedding         0.01%      20.000us         0.03%      72.000us      36.000us       0.000us         0.00%       6.000us       3.000us           0 b           0 b     441.00 Kb           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_2                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::reshape         0.00%       3.000us         0.00%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_2                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                             aten::view         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_2                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                     aten::index_select         0.01%      23.000us         0.02%      49.000us      24.500us       6.000us         0.01%       6.000us       3.000us           0 b           0 b     441.00 Kb           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_2                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::empty         0.01%      14.000us         0.01%      14.000us       3.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       3.28 Mb       3.28 Mb             4  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_2                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::resize_         0.00%       8.000us         0.00%       8.000us       4.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     441.00 Kb     441.00 Kb             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_2                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.01%      31.000us         0.01%      31.000us       5.167us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_2                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us       6.000us         0.01%       6.000us       3.000us           0 b           0 b           0 b           0 b             2  <built-in method embedding of type object at 0x7ff563e97aa0>                 \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2122): embedding                                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/sparse.py(161): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Embedding_2                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                             aten::add_         0.02%      38.000us         0.02%      48.000us      24.000us       8.000us         0.01%       8.000us       4.000us           0 b           0 b           0 b           0 b             2  transformers/models/bert/modeling_bert.py(202): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertEmbeddings_0                                                  \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       8.000us         0.01%       8.000us       4.000us           0 b           0 b           0 b           0 b             2  transformers/models/bert/modeling_bert.py(202): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: BertEmbeddings_0                                                  \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(904): forward                      \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       aten::layer_norm         0.03%      65.000us         0.08%     164.000us      54.667us       0.000us         0.00%      13.000us       4.333us           0 b           0 b       6.01 Mb       2.00 Mb             3  <built-in method layer_norm of type object at 0x7ff563e97aa0>                \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2528): layer_norm                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/normalization.py(195): forward                              \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: LayerNorm_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                aten::native_layer_norm         0.03%      58.000us         0.05%      99.000us      49.500us      13.000us         0.02%      13.000us       6.500us           0 b           0 b       4.01 Mb           0 b             2  <built-in method layer_norm of type object at 0x7ff563e97aa0>                \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2528): layer_norm                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/normalization.py(195): forward                              \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: LayerNorm_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                            aten::empty         0.02%      48.000us         0.02%      48.000us       4.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       7.75 Mb       7.75 Mb            12  <built-in method layer_norm of type object at 0x7ff563e97aa0>                \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2528): layer_norm                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/normalization.py(195): forward                              \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: LayerNorm_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.01%      32.000us         0.01%      32.000us       5.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  <built-in method layer_norm of type object at 0x7ff563e97aa0>                \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2528): layer_norm                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/normalization.py(195): forward                              \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: LayerNorm_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us      13.000us         0.02%      13.000us       6.500us           0 b           0 b           0 b           0 b             2  <built-in method layer_norm of type object at 0x7ff563e97aa0>                \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2528): layer_norm                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/normalization.py(195): forward                              \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: LayerNorm_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                             aten::view         0.00%       1.000us         0.00%       1.000us       0.250us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  <built-in method layer_norm of type object at 0x7ff563e97aa0>                \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(2528): layer_norm                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/normalization.py(195): forward                              \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: LayerNorm_0                                                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::dropout         0.00%       7.000us         0.04%      97.000us      48.500us       0.000us         0.00%       8.000us       4.000us           0 b           0 b       4.86 Mb           0 b             2  <built-in method dropout of type object at 0x7ff563e97aa0>                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(1249): dropout                                        \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/dropout.py(57): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Dropout_0                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                   aten::native_dropout         0.02%      44.000us         0.04%      90.000us      45.000us       8.000us         0.01%       8.000us       4.000us           0 b           0 b       4.86 Mb           0 b             2  <built-in method dropout of type object at 0x7ff563e97aa0>                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(1249): dropout                                        \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/dropout.py(57): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Dropout_0                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       aten::empty_like         0.01%      13.000us         0.02%      41.000us       6.833us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       8.56 Mb           0 b             6  <built-in method dropout of type object at 0x7ff563e97aa0>                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(1249): dropout                                        \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/dropout.py(57): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Dropout_0                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                    aten::empty_strided         0.01%      20.000us         0.01%      20.000us       5.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       4.86 Mb       4.86 Mb             4  <built-in method dropout of type object at 0x7ff563e97aa0>                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(1249): dropout                                        \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/dropout.py(57): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Dropout_0                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                  cudaStreamIsCapturing         0.00%       2.000us         0.00%       2.000us       1.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  <built-in method dropout of type object at 0x7ff563e97aa0>                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(1249): dropout                                        \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/dropout.py(57): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Dropout_0                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         0.01%      26.000us         0.01%      26.000us       6.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  <built-in method dropout of type object at 0x7ff563e97aa0>                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(1249): dropout                                        \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/dropout.py(57): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Dropout_0                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us       8.000us         0.01%       8.000us       4.000us           0 b           0 b           0 b           0 b             2  <built-in method dropout of type object at 0x7ff563e97aa0>                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/functional.py(1249): dropout                                        \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/dropout.py(57): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Dropout_0                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                           aten::linear         0.02%      40.000us         0.28%     612.000us     153.000us       0.000us         0.00%      96.000us      24.000us           0 b           0 b       9.17 Mb           0 b             4  <built-in function linear>                                                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/linear.py(113): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Linear_0                                                          \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(276): forward                      \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                               aten::to         0.02%      52.000us         0.12%     266.000us      22.167us       0.000us         0.00%      45.000us       3.750us           0 b           0 b      13.93 Mb       2.25 Mb            12  <built-in function linear>                                                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/linear.py(113): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Linear_0                                                          \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(276): forward                      \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                         aten::_to_copy         0.03%      61.000us         0.12%     254.000us      21.167us       0.000us         0.00%      54.000us       4.500us           0 b           0 b      13.93 Mb           0 b            12  <built-in function linear>                                                   \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/linear.py(113): forward                                     \n",
      "                                                                                                                                                                                                                                                             torch/nn/modules/module.py(1520): _call_impl                                 \n",
      "                                                                                                                                                                                                                                                             nn.Module: Linear_0                                                          \n",
      "                                                                                                                                                                                                                                                             transformers/models/bert/modeling_bert.py(276): forward                      \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "Self CPU time total: 218.032ms\n",
      "Self CUDA time total: 57.490ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following cell magic if tensorboard is exported. Notice that if tensorboard handler is used to export tensorboard profiling results, the profiler cannot export any more other traces.\n",
    "    \n",
    "    ```python\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir /home/kwu/cupy-playground/intrasm_engine/benchmark/test_tensorboard\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6013 (pid 2407179), started 0:02:11 ago. (Use '!kill 2407179' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1a3d1fa7bc8960a9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1a3d1fa7bc8960a9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "prof.export_chrome_trace(\"chrome_trace.json\")\n",
    "prof.export_stacks(\"stacks.json\", \"self_cuda_time_total\")\n",
    "# use Brendan Gregg's FlameGraph tool to generate flamegraph/flamechart\n",
    "# git clone https://github.com/brendangregg/FlameGraph\n",
    "# ../FlameGraph/flamegraph.pl --title \"FlameGraph\" --countname \"us.\" stacks.json > perf_viz.svg\n",
    "# ../FlameGraph/flamegraph.pl --title \"FlameChart\" --countname \"us.\" --flamechart stacks.json > perf_chart.svg\n",
    "!/home/kwu/FlameGraph/flamegraph.pl --title \"FlameGraph\" --countname \"us.\" stacks.json > perf_viz.svg\n",
    "!/home/kwu/FlameGraph/flamegraph.pl --title \"FlameChart\" --countname \"us.\" --flamechart stacks.json > perf_chart.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "STAGE:2024-01-17 12:32:35 2364529:2364529 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='459' max='459' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [459/459 00:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.496185</td>\n",
       "      <td>0.840686</td>\n",
       "      <td>0.891122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwu/anaconda3/envs/dev_cupy_graph/lib/python3.11/site-packages/datasets/load.py:752: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "STAGE:2024-01-17 12:33:09 2364529:2364529 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-01-17 12:33:11 2364529:2364529 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "# The following code produce order of magnitude larger trace file and takes much longer to run\n",
    "# Use with caution\n",
    "if False:\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    with torch.autograd.profiler.profile(\n",
    "            # on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
    "            #    \"hf-training-trainer\"\n",
    "            # ), # This saves the trace to disk\n",
    "            with_modules=True,\n",
    "            # The following is needed to not export empty stack https://github.com/pytorch/pytorch/issues/100253#issuecomment-1579804477\n",
    "            experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True),\n",
    "        ) as prof2:\n",
    "        trainer.train()\n",
    "    prof2.export_chrome_trace(\"chrome_trace2.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_cupy_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
